{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Dataset"
      ],
      "metadata": {
        "id": "eAhkqu5gceYx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NL5_7TJMaEHS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/spam.csv')\n",
        "df.shape"
      ],
      "metadata": {
        "id": "usngc9Amadbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "cNaTaIEWahVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking for null values"
      ],
      "metadata": {
        "id": "oxkfw_zXcmld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "Js6t4ivWa89K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning and Preprocessing"
      ],
      "metadata": {
        "id": "srYYa_cgfCX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "9DnL5vMYbNwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processing(sent):\n",
        "  lm = WordNetLemmatizer()\n",
        "  # tokenization\n",
        "  sent = re.sub('[^a-zA-Z0-9]',' ',sent)\n",
        "  sent = sent.lower()\n",
        "  review = sent.split()\n",
        "  clean_words = []\n",
        "\n",
        "  for word in review:\n",
        "    # stopwords\n",
        "    if word not in stopwords.words('english'):\n",
        "      # stemming\n",
        "      word = lm.lemmatize(word)\n",
        "      clean_words.append(word)\n",
        "\n",
        "  sent = ' '.join(clean_words)\n",
        "\n",
        "  return sent"
      ],
      "metadata": {
        "id": "P0gSjzt7bZYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text pre-processing"
      ],
      "metadata": {
        "id": "fH9Tskes2zv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index, rows in df.iterrows():\n",
        "  sent = df.loc[index,'message']\n",
        "  sent = processing(sent)\n",
        "  df.loc[index,'cleaned_messages'] = sent"
      ],
      "metadata": {
        "id": "jq2N-mJCbkeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "4SJGotBKbvYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, rows in df.iterrows():\n",
        "  if rows['label'] == 'ham':\n",
        "    rows['label'] = 0\n",
        "  else:\n",
        "    rows['label'] = 1"
      ],
      "metadata": {
        "id": "xN2JSsyvzfad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Ad5-FLLW3IHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['message'],inplace=True)"
      ],
      "metadata": {
        "id": "Nk-NwmNH3Lbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "eG6HfJbg5iL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frequency of messages of different lengths"
      ],
      "metadata": {
        "id": "nLFZxQvm-aSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "length_of_ham_sentences = df['cleaned_messages'][df['label']==0].str.len()\n",
        "length_of_spam_sentences = df['cleaned_messages'][df['label']==1].str.len()\n",
        "\n",
        "plt.hist(length_of_ham_sentences, color='blue')\n",
        "plt.title('ham_messages')\n",
        "plt.xlabel('length of sentences')\n",
        "plt.ylabel('count')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(length_of_spam_sentences, color='orange')\n",
        "plt.title('spam_messages')\n",
        "plt.xlabel('length of sentences')\n",
        "plt.ylabel('count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1V_G2N2c5sOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ham cloud\n",
        "ham_words =' '.join([text for text in df['cleaned_messages'][df['label'] == 0]])\n",
        "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(ham_words)\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WNdoBcRr6GXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spam cloud\n",
        "spam_words =' '.join([text for text in df['cleaned_messages'][df['label'] == 1]])\n",
        "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(spam_words)\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yAErLPDf-Cs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word-embedding"
      ],
      "metadata": {
        "id": "qzD0vGSVDrrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = list(df['cleaned_messages'])\n",
        "# corpus"
      ],
      "metadata": {
        "id": "V3lUuPHu-Nki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BOW technique"
      ],
      "metadata": {
        "id": "92PnvojDHPnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "1BjiG5PcDirP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(binary=True,ngram_range=(1,2))\n",
        "X = cv.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "yJ42AEEVGlnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cv.vocabulary_"
      ],
      "metadata": {
        "id": "wgDBiTbEG06U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "pEKBj7N9ID-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0].toarray()"
      ],
      "metadata": {
        "id": "uNg4oUJkGvr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = list(df['label'])"
      ],
      "metadata": {
        "id": "6Ec2-Ou3OYMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelling"
      ],
      "metadata": {
        "id": "PZqwZpl6OKbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "EGHEfDpSONrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "APvfnIPuONoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
      ],
      "metadata": {
        "id": "GGyBrfsSONmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "FqewddMUO7Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "uBTPp-N-O8DC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy"
      ],
      "metadata": {
        "id": "56wAKbe3RZVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_pred,y_test))"
      ],
      "metadata": {
        "id": "S9COV4MxO9P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "wQxaPRZAHU2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "fcNI2PKRGy8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv = TfidfVectorizer(ngram_range=(1,3))\n",
        "X = tv.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "bKthfDVAKmrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tv.vocabulary_"
      ],
      "metadata": {
        "id": "0Rc3d-2BK1D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "OuZqJRKuLELM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0].toarray()"
      ],
      "metadata": {
        "id": "1KbDDf1ZLJ7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = list(df['label'])"
      ],
      "metadata": {
        "id": "uohqbL8OLMCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelling"
      ],
      "metadata": {
        "id": "BrN0itpBR3CB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "GFNg6y1FRpVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
      ],
      "metadata": {
        "id": "F8H7bHXrRs7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "09Olt1y1RvHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy"
      ],
      "metadata": {
        "id": "BIgveN7jR0MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_pred,y_test))"
      ],
      "metadata": {
        "id": "GEKwk0j8RxhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec (Transfer Learning)"
      ],
      "metadata": {
        "id": "fevMH-ckSIZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gensim"
      ],
      "metadata": {
        "id": "N-31H8MhR65-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "RhwgrzgIPiRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading pre-trained w2v model on google news data\n",
        "wv = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "id": "PrJLcVQ3PpiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functionalities provided by pre-trained model"
      ],
      "metadata": {
        "id": "kxcZrXbVQpdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word vector access\n",
        "print(wv['king'])"
      ],
      "metadata": {
        "id": "PCnoPrd5Pwri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word similarity (similarity = 1-cosine similarity)\n",
        "print(wv.similarity('apple','orange'))"
      ],
      "metadata": {
        "id": "SRP8hlXeRoH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# most similar words\n",
        "print(wv.most_similar('king',topn=5))"
      ],
      "metadata": {
        "id": "WK74HSxuUvLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word vector operations\n",
        "vec = wv['king'] - wv['man'] + wv['woman']\n",
        "print(wv.most_similar(vec,topn=5))"
      ],
      "metadata": {
        "id": "AjdVa2OgUw-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word tokenization\n",
        "words = []\n",
        "\n",
        "for sent in corpus:\n",
        "  words.append(sent.split())"
      ],
      "metadata": {
        "id": "YRyNUHzhUx8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avg_Word2Vec"
      ],
      "metadata": {
        "id": "RiMPm8-HjYcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_word2vec(doc):\n",
        "\n",
        "  if len(doc)==0:\n",
        "    return np.zeros(300)\n",
        "\n",
        "  if doc[0] not in wv.index_to_key:\n",
        "      return np.zeros(300)\n",
        "\n",
        "  temp = np.zeros(len(wv[doc[0]]))\n",
        "  for words in doc:\n",
        "    if words not in wv.index_to_key:\n",
        "      return np.zeros(300)\n",
        "\n",
        "    vec = wv[words]\n",
        "    den = len(vec)\n",
        "    for i in range(den):\n",
        "      temp[i]+=vec[i]\n",
        "  temp/=len(doc)\n",
        "  return temp"
      ],
      "metadata": {
        "id": "ymvfI6aff4xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = np.zeros(300)\n",
        "\n",
        "for i in tqdm(range(len(words))):\n",
        "  X_new = np.vstack((X_new, avg_word2vec(words[i])))"
      ],
      "metadata": {
        "id": "Cgzck538fZCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# words[5]"
      ],
      "metadata": {
        "id": "gLSnuCfikfeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = X_new[1:]\n",
        "X_new.shape"
      ],
      "metadata": {
        "id": "-x0iuTRhfY_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelling"
      ],
      "metadata": {
        "id": "2v_3KXxtjgof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "Pceu45c2fY9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size = 0.20, random_state = 0)"
      ],
      "metadata": {
        "id": "zwDN2NG9fY4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = np.array(X_new)\n",
        "print(X_new.shape, X_new[0].shape)"
      ],
      "metadata": {
        "id": "jp1Hbt4zfrwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "FAPUR7Zsfrtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy"
      ],
      "metadata": {
        "id": "xFb0R4QXjkIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_pred,y_test))"
      ],
      "metadata": {
        "id": "yKby3tyFU_fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### word2vec (training from scratch)"
      ],
      "metadata": {
        "id": "-TUvrF25Wcxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "GHGBD7RqWhC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# words - corpus\n",
        "# window - window's size\n",
        "# min_counts - freq. of words less than min_count will get ignored\n",
        "# vector_size - number of features in output\n",
        "# sg - BOW or SG\n",
        "model = Word2Vec(words, window=5, min_count=0, epochs=10, vector_size=20, sg=1)"
      ],
      "metadata": {
        "id": "QZv0c9BMXSwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary\n",
        "model.wv.index_to_key"
      ],
      "metadata": {
        "id": "pDrdgxdhXsN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of sentences used for network training\n",
        "model.corpus_count"
      ],
      "metadata": {
        "id": "dKQmmfDPX1jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for a word not into vacobulary this will throw an error\n",
        "model.wv['sale']"
      ],
      "metadata": {
        "id": "_Y4DPy_NX4KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avg_Word2Vec"
      ],
      "metadata": {
        "id": "7B4focsJ_7ME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_word2vec(doc):\n",
        "\n",
        "  if len(doc)==0:\n",
        "    return np.zeros(20)\n",
        "\n",
        "  temp = np.zeros(len(model.wv[doc[0]]))\n",
        "  for words in doc:\n",
        "    vec = model.wv[words]\n",
        "    den = len(vec)\n",
        "    for i in range(den):\n",
        "      temp[i]+=vec[i]\n",
        "  temp/=len(doc)\n",
        "  return temp"
      ],
      "metadata": {
        "id": "G7FUXr5qX8T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EVQ-grJFABDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros(20)\n",
        "\n",
        "for i in tqdm(range(len(words))):\n",
        "  X = np.vstack((X, avg_word2vec(words[i])))"
      ],
      "metadata": {
        "id": "kdzDjjkYAdCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[1:]\n",
        "X.shape"
      ],
      "metadata": {
        "id": "5GLEBGTjBM1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "id": "l182_LgxeYFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelling"
      ],
      "metadata": {
        "id": "QEYOJTW0j2_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "6cXPsmVaBeJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
      ],
      "metadata": {
        "id": "pqwe6SJhBu_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "print(X.shape, X[0].shape)"
      ],
      "metadata": {
        "id": "QRXtdmm4CIHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "d0sRM5cTBz2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy"
      ],
      "metadata": {
        "id": "vGk4Es4aj4r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_pred,y_test))"
      ],
      "metadata": {
        "id": "GwYxUPZ0B6X8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}